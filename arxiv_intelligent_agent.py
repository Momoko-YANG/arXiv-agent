#!/usr/bin/env python3
"""
Intelligent arXiv Agent with OpenAI API
é›†æˆ OpenAI GPT çš„æ™ºèƒ½è®ºæ–‡ Agent
"""

import os
import json
from typing import List, Dict, Optional
from datetime import datetime
from arxiv_agent import ArxivAgent
from arxiv_advanced import ArxivDatabase


# ---------------------------------------------------------------------------
# OpenAI å®¢æˆ·ç«¯
# ---------------------------------------------------------------------------
class OpenAIClient:
    """OpenAI ChatCompletion å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str = None, model: str = None):
        """
        Args:
            api_key: OpenAI API Keyï¼Œä¸ä¼ åˆ™è¯» OPENAI_API_KEY ç¯å¢ƒå˜é‡
            model:   é»˜è®¤æ¨¡å‹ï¼Œä¸ä¼ åˆ™ä½¿ç”¨ gpt-4o-miniï¼ˆä¾¿å®œä¸”å¿«ï¼‰
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œæˆ–é€šè¿‡ api_key å‚æ•°ä¼ å…¥"
            )

        self.default_model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")

        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")

    def chat(self, prompt: str, system: str = None, model: str = None) -> str:
        """
        å‘é€ ChatCompletion è¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰

        Args:
            prompt: ç”¨æˆ·æ¶ˆæ¯
            system: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            model:  è¦†ç›–é»˜è®¤æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        """
        import time

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        for attempt in range(3):
            try:
                response = self.client.chat.completions.create(
                    model=model or self.default_model,
                    messages=messages,
                    max_tokens=2000,
                    temperature=0.3,
                )
                return response.choices[0].message.content
            except Exception as e:
                if attempt < 2:
                    wait = 2 ** (attempt + 1)  # 2s, 4s
                    print(f"    âš ï¸  OpenAI è¯·æ±‚å¤±è´¥ï¼Œ{wait}s åé‡è¯•: {e}")
                    time.sleep(wait)
                else:
                    raise


# ---------------------------------------------------------------------------
# æ™ºèƒ½ arXiv Agent
# ---------------------------------------------------------------------------
class IntelligentArxivAgent:
    """æ™ºèƒ½ arXiv Agentï¼ˆä½¿ç”¨ OpenAI GPT åšç­›é€‰ / æ‘˜è¦ / é—®ç­”ï¼‰"""

    def __init__(self,
                 categories: List[str],
                 api_key: str = None,
                 model: str = None,
                 db_path: str = "arxiv_intelligent.db"):
        """
        Args:
            categories: å…³æ³¨çš„ arXiv åˆ†ç±»
            api_key:    OpenAI API Key
            model:      GPT æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gpt-4o-miniï¼‰
            db_path:    SQLite æ•°æ®åº“è·¯å¾„
        """
        self.arxiv_agent = ArxivAgent(categories=categories)
        self.db = ArxivDatabase(db_path=db_path)
        self.llm = OpenAIClient(api_key=api_key, model=model)
        self.categories = categories

    # ---------- ä¸»æµç¨‹ ----------

    def fetch_and_analyze(self,
                          days: int = 1,
                          research_interests: str = None,
                          auto_summarize: bool = True) -> Dict:
        """æŠ“å–å¹¶æ™ºèƒ½åˆ†æè®ºæ–‡"""
        print(f"\n{'=' * 80}")
        print(f"å¼€å§‹æ™ºèƒ½æŠ“å–ä¸åˆ†æ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'=' * 80}\n")

        # 1. æŠ“å–è®ºæ–‡
        print("ğŸ“¥ æ­£åœ¨ä» arXiv æŠ“å–è®ºæ–‡...")
        papers = self.arxiv_agent.fetch_recent_papers(days=days, max_results=100)

        if not papers:
            print("âŒ æ²¡æœ‰æŠ“å–åˆ°è®ºæ–‡")
            return {"papers": [], "relevant": [], "summaries": {}}

        print(f"âœ… æˆåŠŸæŠ“å– {len(papers)} ç¯‡è®ºæ–‡\n")

        # 2. æ™ºèƒ½ç­›é€‰
        relevant_papers = papers
        if research_interests:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ GPT æ™ºèƒ½ç­›é€‰ç›¸å…³è®ºæ–‡...")
            relevant_papers = self.filter_relevant_papers(papers, research_interests)
            print(f"âœ… ç­›é€‰å‡º {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡\n")

        # 3. ç”Ÿæˆä¸­æ–‡æ‘˜è¦
        summaries = {}
        if auto_summarize and relevant_papers:
            import time
            n = min(len(relevant_papers), 5)
            print(f"ğŸ“ æ­£åœ¨ä¸º {n} ç¯‡è®ºæ–‡ç”Ÿæˆä¸­æ–‡æ‘˜è¦...")
            for i, paper in enumerate(relevant_papers[:5], 1):
                print(f"  å¤„ç† {i}/{n}: {paper['title'][:50]}...")
                summary = self.summarize_paper(paper)
                if not summary.startswith("æ‘˜è¦ç”Ÿæˆå¤±è´¥"):
                    summaries[paper['arxiv_id']] = summary
                else:
                    print(f"    âŒ {summary}")
                # æ¯æ¬¡è¯·æ±‚é—´éš” 1 ç§’ï¼Œé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                if i < n:
                    time.sleep(1)
            print(f"  âœ… æˆåŠŸç”Ÿæˆ {len(summaries)}/{n} ç¯‡æ‘˜è¦")
            print()

        # 4. ä¿å­˜åˆ°æ•°æ®åº“
        print("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        new_count = sum(1 for p in papers if self.db.insert_paper(p))
        print(f"âœ… æ–°å¢ {new_count} ç¯‡è®ºæ–‡åˆ°æ•°æ®åº“\n")

        return {
            "papers": papers,
            "relevant": relevant_papers,
            "summaries": summaries,
        }

    # ---------- ç­›é€‰ ----------

    def filter_relevant_papers(self,
                               papers: List[Dict],
                               research_interests: str,
                               top_k: int = 10) -> List[Dict]:
        """ä½¿ç”¨ GPT ç­›é€‰ä¸ç ”ç©¶æ–¹å‘æœ€ç›¸å…³çš„è®ºæ–‡"""
        papers_text = []
        for i, paper in enumerate(papers):
            papers_text.append(
                f"{i+1}. ID: {paper['arxiv_id']}\n"
                f"   æ ‡é¢˜: {paper['title']}\n"
                f"   æ‘˜è¦: {paper['summary'][:300]}...\n"
            )

        prompt = f"""æˆ‘çš„ç ”ç©¶å…´è¶£æ˜¯ï¼š{research_interests}

ä»¥ä¸‹æ˜¯æœ€è¿‘çš„ arXiv è®ºæ–‡åˆ—è¡¨ï¼š

{''.join(papers_text)}

è¯·åˆ†æå“ªäº›è®ºæ–‡ä¸æˆ‘çš„ç ”ç©¶å…´è¶£æœ€ç›¸å…³ã€‚

è¦æ±‚ï¼š
1. è¿”å›æœ€ç›¸å…³çš„ {top_k} ç¯‡è®ºæ–‡çš„ IDï¼ˆæ ¼å¼å¦‚ 2402.12345ï¼‰
2. æ¯ä¸ª ID å ä¸€è¡Œ
3. æŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åº
4. åªè¿”å› ID åˆ—è¡¨ï¼Œä¸è¦å…¶ä»–è§£é‡Š

æ ¼å¼ç¤ºä¾‹ï¼š
2402.12345
2402.12346
"""
        system = "ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡åˆ†æä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ç ”ç©¶æ–¹å‘ç­›é€‰ç›¸å…³è®ºæ–‡ã€‚"

        try:
            response = self.llm.chat(prompt, system=system)

            relevant_ids = []
            for line in response.strip().split('\n'):
                line = line.strip()
                if len(line) >= 10 and '.' in line:
                    relevant_ids.append(line)

            id_to_paper = {p['arxiv_id']: p for p in papers}
            relevant_papers = [id_to_paper[aid] for aid in relevant_ids if aid in id_to_paper]
            return relevant_papers[:top_k]

        except Exception as e:
            print(f"âš ï¸  ç­›é€‰å¤±è´¥: {e}")
            return papers[:top_k]

    # ---------- æ‘˜è¦ ----------

    def summarize_paper(self, paper: Dict, language: str = 'zh') -> str:
        """ç”Ÿæˆè®ºæ–‡ä¸­æ–‡/è‹±æ–‡æ‘˜è¦"""
        lang_name = "ä¸­æ–‡" if language == 'zh' else "English"

        prompt = f"""è¯·ç”¨{lang_name}æ€»ç»“è¿™ç¯‡è®ºæ–‡ï¼š

æ ‡é¢˜: {paper['title']}

æ‘˜è¦: {paper['summary']}

è¦æ±‚ï¼š
1. ç”¨ 2-3 å¥è¯æ¦‚æ‹¬æ ¸å¿ƒå†…å®¹
2. çªå‡ºåˆ›æ–°ç‚¹å’Œä¸»è¦è´¡çŒ®
3. ä½¿ç”¨ç®€æ´çš„å­¦æœ¯è¯­è¨€
4. å¦‚æœæ˜¯ä¸­æ–‡ï¼Œä½¿ç”¨ä¸­æ–‡ä¸“ä¸šæœ¯è¯­
"""
        system = f"ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡æ€»ç»“ä¸“å®¶ï¼Œæ“…é•¿ç”¨{lang_name}æ¸…æ™°ç®€æ´åœ°æ€»ç»“è®ºæ–‡æ ¸å¿ƒå†…å®¹ã€‚"

        try:
            return self.llm.chat(prompt, system=system).strip()
        except Exception as e:
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"

    # ---------- é—®ç­” ----------

    def ask_question(self, question: str, context_days: int = 7) -> str:
        """å¯¹è¯å¼æ£€ç´¢è®ºæ–‡"""
        papers = self.db.get_recent_papers(days=context_days, limit=50)
        if not papers:
            return "æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡ã€‚"

        context = []
        for paper in papers:
            context.append(
                f"- {paper['title']}\n"
                f"  ID: {paper['arxiv_id']}, å‘å¸ƒ: {paper['published']}\n"
            )

        prompt = f"""åŸºäºä»¥ä¸‹æœ€è¿‘ {context_days} å¤©çš„ arXiv è®ºæ–‡ï¼š

{''.join(context)}

è¯·å›ç­”ï¼š{question}

è¦æ±‚ï¼š
1. åŸºäºæä¾›çš„è®ºæ–‡åˆ—è¡¨å›ç­”
2. å¼•ç”¨å…·ä½“çš„è®ºæ–‡ï¼ˆæ ‡é¢˜å’Œ IDï¼‰
3. å¦‚æœæ²¡æœ‰ç›¸å…³è®ºæ–‡ï¼Œè¯·è¯´æ˜
4. ç”¨ä¸­æ–‡å›ç­”
"""
        system = "ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ä»è®ºæ–‡åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        try:
            return self.llm.chat(prompt, system=system)
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥: {e}"

    # ---------- æŠ¥å‘Š ----------

    def generate_daily_report(self, summaries: Dict, relevant_papers: List[Dict]) -> str:
        """ç”Ÿæˆæ¯æ—¥æ™ºèƒ½æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append(f"arXiv æ™ºèƒ½æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        report.append("=" * 80)
        report.append("")

        if not relevant_papers:
            report.append("ä»Šæ—¥æ— ç‰¹åˆ«ç›¸å…³çš„è®ºæ–‡ã€‚")
            return '\n'.join(report)

        report.append(f"ğŸ“Š ä»Šæ—¥å…±å‘ç° {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡")
        report.append("")

        for i, paper in enumerate(relevant_papers, 1):
            report.append(f"## {i}. {paper['title']}")
            report.append(f"**arXiv ID**: {paper['arxiv_id']}")
            authors_str = ', '.join(paper['authors'][:3])
            if len(paper['authors']) > 3:
                authors_str += '...'
            report.append(f"**ä½œè€…**: {authors_str}")
            report.append(f"**åˆ†ç±»**: {', '.join(paper['categories'])}")
            report.append(f"**é“¾æ¥**: https://arxiv.org/abs/{paper['arxiv_id']}")
            report.append("")

            if paper['arxiv_id'] in summaries:
                report.append("**ä¸­æ–‡æ‘˜è¦**:")
                report.append(summaries[paper['arxiv_id']])
            else:
                report.append("**åŸæ–‡æ‘˜è¦**:")
                report.append(paper['summary'][:300] + "...")

            report.append("")
            report.append("-" * 80)
            report.append("")

        return '\n'.join(report)

    def close(self):
        """å…³é—­æ•°æ®åº“"""
        self.db.close()


# ---------------------------------------------------------------------------
# ç‹¬ç«‹è¿è¡Œæ¼”ç¤º
# ---------------------------------------------------------------------------
if __name__ == '__main__':
    categories = ['cs.AI', 'cs.LG', 'cs.CV', 'cs.CL']
    research_interests = """
    æˆ‘å…³æ³¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»¥ä¸‹æ–¹å‘ï¼š
    1. æ¨ç†èƒ½åŠ›æå‡ï¼ˆreasoning, chain-of-thoughtï¼‰
    2. å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆvision-language modelsï¼‰
    3. æ¨¡å‹å‹ç¼©å’Œæ•ˆç‡ä¼˜åŒ–
    4. æç¤ºå·¥ç¨‹å’Œä¸Šä¸‹æ–‡å­¦ä¹ 
    """

    agent = IntelligentArxivAgent(categories=categories)

    try:
        print("=" * 80)
        print("ğŸ¤– æ™ºèƒ½ arXiv Agent æ¼”ç¤º")
        print("=" * 80)

        result = agent.fetch_and_analyze(
            days=1,
            research_interests=research_interests,
            auto_summarize=True,
        )

        report = agent.generate_daily_report(
            summaries=result['summaries'],
            relevant_papers=result['relevant'],
        )

        report_file = f"intelligent_report_{datetime.now().strftime('%Y%m%d')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}\n")

    finally:
        agent.close()
        print("\nâœ… å®Œæˆï¼")
