"""
ä¸‰æ®µå¼è®ºæ–‡æ‘˜è¦å™¨ â€” æŠ½å– â†’ ç»“æ„åŒ– â†’ å‹ç¼©é‡å†™
"""

import re
from typing import Dict, List

from .prompt_templates import (
    EXTRACT_SYSTEM, EXTRACT_PROMPT,
    COMPRESS_SYSTEM_ZH, COMPRESS_PROMPT_ZH,
    COMPRESS_SYSTEM_EN, COMPRESS_PROMPT_EN,
)


# ---------------------------------------------------------------------------
# Stage 1: å…³é”®å¥æŠ½å–ï¼ˆè§„åˆ™å±‚ï¼Œ0 tokenï¼‰
# ---------------------------------------------------------------------------

_METHOD_KW = {
    "propose", "present", "introduce", "develop", "design",
    "method", "approach", "framework", "architecture", "model",
    "algorithm", "technique", "mechanism", "strategy", "pipeline",
    "leverage", "employ", "utilize", "formulate", "novel",
}

_RESULT_KW = {
    "experiment", "result", "evaluation", "benchmark", "dataset",
    "outperform", "improve", "achieve", "surpass", "state-of-the-art",
    "sota", "accuracy", "performance", "f1", "bleu", "rouge",
    "demonstrate", "show", "significantly", "superior", "comparable",
    "reduce", "increase", "gain",
}

_PROBLEM_KW = {
    "challenge", "problem", "limitation", "issue", "gap",
    "lack", "suffer", "difficult", "bottleneck", "drawback",
    "however", "although", "despite", "remain", "existing",
    "struggle", "fail", "inadequate",
}

_ALL_KW = _METHOD_KW | _RESULT_KW | _PROBLEM_KW


def extract_key_sentences(abstract: str, max_sentences: int = 6) -> str:
    """
    è§„åˆ™å±‚å…³é”®å¥æŠ½å–ï¼šå…³é”®è¯åŒ¹é… + ä½ç½®åŠ æƒ
    """
    text = abstract.replace("et al.", "et al").replace("i.e.", "ie").replace("e.g.", "eg")
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())

    if len(sentences) <= max_sentences:
        return abstract

    scored = []
    for i, sent in enumerate(sentences):
        lower = sent.lower()
        hits = sum(1 for kw in _ALL_KW if kw in lower)
        if i == 0:
            hits += 2  # é¦–å¥é€šå¸¸æ˜¯é—®é¢˜é™ˆè¿°
        elif i == len(sentences) - 1:
            hits += 1  # å°¾å¥é€šå¸¸æ˜¯æ€»ç»“
        scored.append((i, hits, sent))

    scored.sort(key=lambda x: x[1], reverse=True)
    top = sorted(scored[:max_sentences], key=lambda x: x[0])  # æ¢å¤åŸæ–‡é¡ºåº

    return " ".join(item[2] for item in top) or abstract


# ---------------------------------------------------------------------------
# PaperSummarizer ä¸»ç±»
# ---------------------------------------------------------------------------

class PaperSummarizer:
    """
    ä¸‰æ®µå¼è®ºæ–‡æ‘˜è¦å™¨

    Pipeline:
        abstract â†’ extract_key_sentences  [è§„åˆ™å±‚ï¼Œ0 token]
                 â†’ structured_extract     [LLMï¼šæå– problem/method/result]
                 â†’ compress_summary       [LLMï¼šå‹ç¼©é‡å†™ä¸º 3 ä¸ªè¦ç‚¹]
    """

    def __init__(self, llm_client=None, language: str = "zh"):
        """
        Args:
            llm_client: utils.llm_client.OpenAIClient å®ä¾‹
            language:   è¾“å‡ºè¯­è¨€ 'zh' æˆ– 'en'
        """
        self.llm = llm_client
        self.language = language

    def structured_extract(self, key_text: str, title: str) -> str:
        """Stage 2: ç»“æ„åŒ–ä¿¡æ¯æŠ½å–ï¼ˆProblem / Method / Resultï¼‰"""
        prompt = EXTRACT_PROMPT.format(key_text=key_text, title=title)
        try:
            return self.llm.chat(prompt, system=EXTRACT_SYSTEM, temperature=0.2).strip()
        except Exception as e:
            return f"- Problem: extraction failed\n- Method: {title}\n- Result: see paper ({e})"

    def compress_summary(self, structured_text: str, title: str) -> str:
        """Stage 3: è¯­ä¹‰å‹ç¼©é‡å†™"""
        if self.language == "zh":
            prompt = COMPRESS_PROMPT_ZH.format(structured=structured_text, title=title)
            system = COMPRESS_SYSTEM_ZH
        else:
            prompt = COMPRESS_PROMPT_EN.format(structured=structured_text, title=title)
            system = COMPRESS_SYSTEM_EN
        try:
            return self.llm.chat(prompt, system=system, temperature=0.6).strip()
        except Exception as e:
            return f"â€¢ æ‘˜è¦å‹ç¼©å¤±è´¥: {e}"

    def summarize(self, paper: Dict) -> str:
        """å®Œæ•´ä¸‰æ®µå¼æ‘˜è¦"""
        title = paper.get("title", "")
        abstract = paper.get("summary", "")
        if not abstract:
            return "â€¢ æ— æ‘˜è¦ä¿¡æ¯"

        key_text = extract_key_sentences(abstract)
        structured = self.structured_extract(key_text, title)
        return self.compress_summary(structured, title)

    def summarize_batch(self, papers: List[Dict],
                        delay: float = 1.0) -> Dict[str, str]:
        """
        æ‰¹é‡æ‘˜è¦

        Returns:
            {arxiv_id: summary_text}
        """
        import time

        results = {}
        total = len(papers)

        for i, paper in enumerate(papers, 1):
            arxiv_id = paper.get("arxiv_id", f"unknown_{i}")
            print(f"  ğŸ§  [{i}/{total}] ä¸‰æ®µå¼æ‘˜è¦: {paper.get('title', '')[:50]}...")

            summary = self.summarize(paper)
            if summary and not summary.startswith("â€¢ æ‘˜è¦å‹ç¼©å¤±è´¥"):
                results[arxiv_id] = summary
                first_line = summary.split("\n")[0]
                print(f"       â†’ {first_line}")
            else:
                print(f"       âŒ {summary}")

            if i < total and delay > 0:
                time.sleep(delay)

        return results
