"""
ä¸‰æ®µå¼è®ºæ–‡æ‘˜è¦å™¨ â€” æŠ½å– â†’ ç»“æ„åŒ– â†’ å‹ç¼©é‡å†™
å½“ LLM ä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§ä¸ºè§„åˆ™æ‘˜è¦
"""

import re
from typing import Dict, List

from .prompt_templates import (
    EXTRACT_SYSTEM, EXTRACT_PROMPT,
    COMPRESS_SYSTEM_ZH, COMPRESS_PROMPT_ZH,
    COMPRESS_SYSTEM_EN, COMPRESS_PROMPT_EN,
)


# ---------------------------------------------------------------------------
# Stage 1: å…³é”®å¥æŠ½å–ï¼ˆè§„åˆ™å±‚ï¼Œ0 tokenï¼‰
# ---------------------------------------------------------------------------

_METHOD_KW = {
    "propose", "present", "introduce", "develop", "design",
    "method", "approach", "framework", "architecture", "model",
    "algorithm", "technique", "mechanism", "strategy", "pipeline",
    "leverage", "employ", "utilize", "formulate", "novel",
}

_RESULT_KW = {
    "experiment", "result", "evaluation", "benchmark", "dataset",
    "outperform", "improve", "achieve", "surpass", "state-of-the-art",
    "sota", "accuracy", "performance", "f1", "bleu", "rouge",
    "demonstrate", "show", "significantly", "superior", "comparable",
    "reduce", "increase", "gain",
}

_PROBLEM_KW = {
    "challenge", "problem", "limitation", "issue", "gap",
    "lack", "suffer", "difficult", "bottleneck", "drawback",
    "however", "although", "despite", "remain", "existing",
    "struggle", "fail", "inadequate",
}

_ALL_KW = _METHOD_KW | _RESULT_KW | _PROBLEM_KW


def extract_key_sentences(abstract: str, max_sentences: int = 6) -> str:
    """è§„åˆ™å±‚å…³é”®å¥æŠ½å–ï¼šå…³é”®è¯åŒ¹é… + ä½ç½®åŠ æƒ"""
    text = abstract.replace("et al.", "et al").replace("i.e.", "ie").replace("e.g.", "eg")
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())

    if len(sentences) <= max_sentences:
        return abstract

    scored = []
    for i, sent in enumerate(sentences):
        lower = sent.lower()
        hits = sum(1 for kw in _ALL_KW if kw in lower)
        if i == 0:
            hits += 2
        elif i == len(sentences) - 1:
            hits += 1
        scored.append((i, hits, sent))

    scored.sort(key=lambda x: x[1], reverse=True)
    top = sorted(scored[:max_sentences], key=lambda x: x[0])

    return " ".join(item[2] for item in top) or abstract


# ---------------------------------------------------------------------------
# PaperSummarizer ä¸»ç±»
# ---------------------------------------------------------------------------

class PaperSummarizer:
    """
    ä¸‰æ®µå¼è®ºæ–‡æ‘˜è¦å™¨

    Pipeline:
        abstract â†’ extract_key_sentences  [è§„åˆ™å±‚ï¼Œ0 token]
                 â†’ structured_extract     [LLMï¼šæå– problem/method/result]
                 â†’ compress_summary       [LLMï¼šå‹ç¼©é‡å†™ä¸º 3 ä¸ªè¦ç‚¹]

    å½“ LLM è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é™çº§ä¸ºè§„åˆ™æ‘˜è¦
    """

    def __init__(self, llm_client=None, language: str = "zh"):
        self.llm = llm_client
        self.language = language
        self._llm_failures = 0  # è¿ç»­å¤±è´¥è®¡æ•°

    def structured_extract(self, key_text: str, title: str) -> str:
        """Stage 2: ç»“æ„åŒ–ä¿¡æ¯æŠ½å–"""
        prompt = EXTRACT_PROMPT.format(key_text=key_text, title=title)
        try:
            result = self.llm.chat(prompt, system=EXTRACT_SYSTEM, temperature=0.2).strip()
            self._llm_failures = 0
            return result
        except Exception as e:
            self._llm_failures += 1
            return f"- Problem: extraction failed\n- Method: {title}\n- Result: see paper ({e})"

    def compress_summary(self, structured_text: str, title: str) -> str:
        """Stage 3: è¯­ä¹‰å‹ç¼©é‡å†™"""
        if self.language == "zh":
            prompt = COMPRESS_PROMPT_ZH.format(structured=structured_text, title=title)
            system = COMPRESS_SYSTEM_ZH
        else:
            prompt = COMPRESS_PROMPT_EN.format(structured=structured_text, title=title)
            system = COMPRESS_SYSTEM_EN
        try:
            result = self.llm.chat(prompt, system=system, temperature=0.6).strip()
            self._llm_failures = 0
            return result
        except Exception as e:
            self._llm_failures += 1
            return f"â€¢ æ‘˜è¦å‹ç¼©å¤±è´¥: {e}"

    def _rule_based_summary(self, paper: Dict) -> str:
        """çº¯è§„åˆ™é™çº§æ‘˜è¦ï¼ˆ0 tokenï¼Œå³æ—¶å®Œæˆï¼‰"""
        abstract = paper.get("summary", "")
        if not abstract:
            return "â€¢ æ— æ‘˜è¦ä¿¡æ¯"
        key = extract_key_sentences(abstract, max_sentences=3)
        if len(key) > 250:
            key = key[:247] + "..."
        return f"â€¢ {key}"

    def summarize(self, paper: Dict) -> str:
        """å®Œæ•´ä¸‰æ®µå¼æ‘˜è¦ï¼ŒLLM å¤±è´¥è‡ªåŠ¨é™çº§"""
        title = paper.get("title", "")
        abstract = paper.get("summary", "")
        if not abstract:
            return "â€¢ æ— æ‘˜è¦ä¿¡æ¯"

        # è¿ç»­å¤±è´¥è¾ƒå¤šæ—¶å†å…¨å±€é™çº§ï¼Œé¿å…è¿‡æ—©æ”¾å¼ƒ LLM
        if self._llm_failures >= 6:
            return self._rule_based_summary(paper)

        key_text = extract_key_sentences(abstract)
        structured = self.structured_extract(key_text, title)

        # å¦‚æœç»“æ„åŒ–æå–å¤±è´¥äº†ï¼Œç›´æ¥ç”¨è§„åˆ™æ‘˜è¦
        if "extraction failed" in structured:
            return self._rule_based_summary(paper)

        result = self.compress_summary(structured, title)
        if "æ‘˜è¦å‹ç¼©å¤±è´¥" in result:
            return self._rule_based_summary(paper)

        return result

    def summarize_batch(self, papers: List[Dict],
                        delay: float = 0.5) -> Dict[str, str]:
        """
        æ‰¹é‡æ‘˜è¦

        delay: æ¯ç¯‡ä¹‹é—´çš„ç­‰å¾…ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 0.5sï¼ˆæ¯”ä¹‹å‰çš„ 1.0s å¿«ä¸€å€ï¼‰
        """
        import time

        results = {}
        total = len(papers)

        for i, paper in enumerate(papers, 1):
            arxiv_id = paper.get("arxiv_id", f"unknown_{i}")
            title_short = paper.get('title', '')[:50]

            # å¦‚æœ LLM è¿ç»­å¤±è´¥å¾ˆå¤šæ¬¡ï¼Œåç»­èµ°è§„åˆ™æ‘˜è¦
            if self._llm_failures >= 6:
                print(f"  ğŸ“ [{i}/{total}] è§„åˆ™æ‘˜è¦(LLM æ–­è¿): {title_short}...")
                results[arxiv_id] = self._rule_based_summary(paper)
                continue

            print(f"  ğŸ§  [{i}/{total}] ä¸‰æ®µå¼æ‘˜è¦: {title_short}...")

            summary = self.summarize(paper)
            results[arxiv_id] = summary

            first_line = summary.split("\n")[0]
            if "æ‘˜è¦å‹ç¼©å¤±è´¥" in summary or "extraction failed" in summary:
                print(f"       âš ï¸  é™çº§ä¸ºè§„åˆ™æ‘˜è¦")
            else:
                print(f"       â†’ {first_line[:60]}")

            if i < total and delay > 0 and self._llm_failures < 6:
                time.sleep(delay)

        return results
